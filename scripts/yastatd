#!/usr/bin/env python
# -*- coding: UTF-8 -*-
"""Yet Another Statd

Usage: %(program)s [-d]

Options:

    -d
         Turn on debugging prints.

"""

import os
import sys
import time
import json
import yaml
import getopt
import random
import syslog
import logging
import threading
import traceback
import multiprocessing
import socket

from os import path as osp
from datetime import datetime
from copy import deepcopy

if sys.version_info < (2, 6):
    sys.exit('error: Python 2.6 or later required')

from utils import check_dir
from utils import ops_log_open
from stat_linux import sysstat
from utils.sistr import sistr
from utils import nagios
from nagios.check_ssh import check_ssh as _check_ssh
from nagios.check_rsync import check_rsync as _check_rsync
from utils.mail import get_mail_banner, count_mail_queue

# pylint: disable=bare-except
try:
    from importlib import import_module
except:
    import_module = __import__
# pylint: enable=bare-except

program = sys.argv[0]

dir_spool = "/var/spool/yastatd"
dir_json = 'json'

do_exit = threading.Event()
do_debug = False

STATE_OK = 0
STATE_WARNING = 1
STATE_CRITICAL = 2
STATE_UNKNOWN = 3

SECOND = 1
MINUTE = 60 * SECOND

THREAD_MAP = {
    'is_func': 'func_thread',
}


def usage(code, msg=''):
    print >> sys.stderr, __doc__ % globals()
    if msg:
        print >> sys.stderr, msg
    sys.exit(code)


def load_cfg(cfg_file='yastatd.yaml'):
    try:
        work_dir = osp.dirname(osp.realpath(__file__))
        yastat_cfg = yaml.load(open(osp.join(work_dir, cfg_file), "r"))
    except Exception, e:
        yastat_cfg = {}

    if yastat_cfg is None:
        yastat_cfg = {}

    nagios_cfg = yastat_cfg.pop('nagios', {})
    if not nagios_cfg:
        nagios_cfg = {}

    domain = yastat_cfg.pop('domain', None)

    return yastat_cfg, nagios_cfg, domain


def run_stat(**kwargs):
    stats = sysstat()
    for k, v in kwargs.items():
        if not v:
            continue
        module_name = func_name = "stat_%s" % k
        module = import_module(module_name)
        # pylint: disable=star-args
        stats[k] = getattr(module, func_name)(**v)
        # pylint: enable=star-args
    stats['timestamp'] = int(time.time())

    return stats


class base_thread(threading.Thread):
    def __init__(self, **kwargs):
        threading.Thread.__init__(self)
        self.name = self.__class__.__name__
        if sys.hexversion < 0x2070000:
            self.log = ops_log_open(level=logging.INFO)
            syslog.openlog('yastatd', syslog.LOG_PID, syslog.LOG_LOCAL3)
        else:
            self.log = ops_log_open(level=logging.INFO,
                                    syslog={'ident': "yastatd",
                                            'level': logging.INFO})
        self.yastat_cfg = kwargs.get('yastat_cfg', {})
        self.nagios_cfg = kwargs.get('nagios_cfg', {})
        self.domain = kwargs.get('domain')

    def run(self):
        try:
            check_dir(0755, dir_spool)
            os.chdir(dir_spool)
        except Exception, e:
            self.log.critical("%s, %s" % (e, traceback.format_exc()))
        time_current = int(time.time())
        time_last = time_next = time_current

        # calculate every check item's next check time
        check_time_next = {}
        stats_last = {}
        for k, v in self.nagios_cfg.iteritems():
            check_time_next[k] = time_current
            if v.get('is_counter'):
                stats_last[k] = None

        while not do_exit.is_set():
            try:
                time_current = int(time.time())

                # system time changed?
                if time_current < time_last:
                    # delete newer record?
                    pass
                elif time_current >= time_next:
                    if self.name == 'stat_thread':
                        if self.yastat_cfg:
                            stats = run_stat(**self.yastat_cfg)
                        else:
                            stats = run_stat()
                    else:
                        stats = {}

                    nagios_rets = {}
                    for k, v in self.nagios_cfg.iteritems():
                        # control nagios service in which thread
                        _f = False
                        for flag, thread_name in THREAD_MAP.iteritems():
                            if self.name == thread_name and not v.get(flag):
                                _f = True
                        if _f:
                            continue
                        # default thread
                        if self.name == 'stat_thread' and \
                                tuple(set(v.keys()) & set(THREAD_MAP.keys())):
                            continue
                        if time_current >= check_time_next[k]:
                            r = self.run_check(k, v,
                                               stats,
                                               stats_last,
                                               check_time_next)
                            if r: nagios_rets.update(r)

                    if nagios_rets:
                        if do_debug:
                            print json.dumps(nagios_rets, indent=2)
                        else:
                            nagios_rets['rand'] = random.randint(0, 1000)
                            if self.domain:
                                nagios_rets['domain'] = self.domain
                            syslog.syslog(syslog.LOG_NOTICE,
                                          json.dumps(nagios_rets))

                    if self.name == 'stat_thread':
                        if do_debug:
                            #print json.dumps({timestamp: stats}, indent=2)
                            pass
                        else:
                            stat_thread.save_data(stats)
                    time_last = time_current
                    time_next = time_current + MINUTE
            except Exception, e:
                self.log.critical("%s, %s" % (e, traceback.format_exc()))
            time.sleep(SECOND)

    def run_check(self, kind, cfg, stats, stats_last, check_time_next):
        w_t = cfg.get('warning')
        c_t = cfg.get('critical')
        interval = cfg.get('interval')

        time_current = stats.get('timestamp')

        check_thread = getattr(sys.modules[__name__], self.name)
        check_func = getattr(check_thread, 'check_{0}'.format(kind))

        r = None
        stat = stats.get(kind)
        if cfg.get('is_counter'):
            stat_last = stats_last[kind]
            if stat_last:
                time_last = stat_last['timestamp']
                timedelta = time_current - time_last
                r = check_func(stat, stat_last, timedelta, w_t, c_t)
            else:
                # do nothing
                pass
            stats_last[kind] = deepcopy(stat)
            stats_last[kind]['timestamp'] = time_current

            # do not store single cpu data
            if kind == 'cpu' and 'cpu' in stats:
                keys = stats['cpu'].keys()
                for k in keys:
                    if k.startswith('cpu'):
                        stats['cpu'].pop(k)
        elif cfg.get('is_func'):
            r = check_func(**cfg)
        else:
            r = check_func(stat, w_t, c_t)

        check_time_next[kind] += interval * MINUTE
        return {kind: r} if r else None


class stat_thread(base_thread):
    '''for stat service'''
    def __init__(self, **kwargs):
        super(stat_thread, self).__init__(**kwargs)

    @staticmethod
    def save_data(stats):
        #  collect data & save to json/yyyymmdd/hhmmss.json
        timestamp = stats.get('timestamp')
        json_datetime = datetime.fromtimestamp(timestamp)
        json_date = json_datetime.strftime('%Y%m%d')
        json_time = json_datetime.strftime('%H%M%S')
        json_dir = osp.join(dir_json, json_date)
        check_dir(0755, dir_json)
        check_dir(0755, json_dir)
        json_file = osp.join(json_dir,
                             '.'.join((json_time, 'json')))
        json_file_tmp = '.'.join((json_file, 'tmp'))

        json.dump({timestamp: stats},
                  open(json_file_tmp, 'w+'),)
        os.rename(json_file_tmp, json_file)

    @staticmethod
    def check_cpu(stat, stat_last, timedelta,
                  threshold_warning, threshold_critical):
        # pylint: disable=too-many-locals
        ret = STATE_OK
        msg = []
        try:
            cpu_count = stat['count']

            def _do_check(k, stat, stat_last):
                '''check total and per cpu'''
                _ret = STATE_OK
                # cpu average every second
                _f = lambda x: x / timedelta / (cpu_count if k=='stat' else 1)
                cpu_sys = _f(stat['sys'] - stat_last['sys'])
                cpu_user = _f(stat['user'] - stat_last['user'])
                cpu_idle = _f(stat['idle'] - stat_last['idle'])
                cpu_iowait = _f(stat['iowait'] - stat_last['iowait'])
                cpu_usage = 100 - cpu_idle - cpu_iowait
                if cpu_usage >= threshold_critical:
                    _ret = STATE_CRITICAL
                elif cpu_usage >= threshold_warning:
                    _ret = STATE_WARNING
                cpu_name = 'cpu' if k == 'stat' else k
                # show total cpu and warning/critical per cpu
                if k == 'stat' or _ret != STATE_OK:
                    msg.append("{0} Usage (user/sys/idle/wait): "
                               "{1}%/{2}%/{3}%/{4}%"
                               .format(cpu_name.upper(), cpu_user, cpu_sys,
                                       cpu_idle, cpu_iowait))
                return _ret

            for k in stat.keys():
                if k == 'stat' or k.startswith('cpu'):
                    cpu_current, cpu_last = stat[k], stat_last[k]
                    _ret = _do_check(k, cpu_current, cpu_last)
                    ret = max(ret, _ret)
        except Exception, e:
            ret = STATE_UNKNOWN
            msg.append('{0}, {1}'.format(e, traceback.format_exc()))

        return (ret, ', '.join(msg))

    @staticmethod
    def check_disk(stat, threshold_warning, threshold_critical):
        ret = STATE_OK
        msg = []
        try:
            for mopt in stat:
                _ds = stat[mopt]
                _percent = int(_ds['used'] * 1.0 / _ds['total'] * 100)
                _unit = _ds['unit']
                # Byte to GByte
                # pylint: disable=cell-var-from-loop
                _f = lambda x: sistr(x * _unit, prec=2)
                # pylint: enable=cell-var-from-loop
                _total = _f(_ds['total'])
                if 'inode' in _ds:
                    _inode = "{0}%".format(_ds.get('inode'))
                else:
                    _inode = 'N/A'
                msg.append("{0} ({1} * {2}%, inode {3})"
                           .format(mopt, _total, _percent, _inode))
                if _percent >= threshold_critical:
                    ret = STATE_CRITICAL
                elif _percent >= threshold_warning and ret != STATE_CRITICAL:
                    ret = STATE_WARNING
        except Exception, e:
            ret = STATE_UNKNOWN
            msg.append('{0}, {1}'.format(e, traceback.format_exc()))

        return (ret, ' '.join(("DISK Usage:", ', '.join(msg))))


class func_thread(base_thread):
    '''for func services'''
    def __init__(self, **kwargs):
        super(func_thread, self).__init__(**kwargs)

    @staticmethod
    def check_ssh(version='2', auth=('publickey',), **param):
        version = str(version)
        # auth: False to disable auth checker
        if not auth:
            auth = None
        ssh_ret = _check_ssh('127.0.0.1', version, auth)
        return ssh_ret

    @staticmethod
    def check_rsync(**param):
        rsync_ret = _check_rsync('127.0.0.1')
        return rsync_ret

    @staticmethod
    def check_mail(mail_type='exim', **param):
        try:
            banner = get_mail_banner()

            _mail_num, _ret_code, _ret_msg = count_mail_queue(mail_type)
            if _ret_code:
                _msg = _ret_msg
                ret = STATE_CRITICAL
            elif _mail_num:
                _msg = '{0} mails in the queue'.format(_mail_num)
                ret = STATE_WARNING
            else:
                _msg = banner
                ret = STATE_OK
        except socket.error as e:
            _msg = 'mail process not running'
            ret = STATE_CRITICAL
        except Exception as e:
            _msg = str(e)
            ret = STATE_UNKNOWN

        msg = "Mail({0}) {1} - {2}".format(mail_type, nagios.STATE_STR[ret],
                                           _msg)

        return (ret, msg)


class zmq_thread(threading.Thread):
    def __init__(self):
        threading.Thread.__init__(self)
        self.name = "zmq_thread"

    def run(self):
        while not do_exit.is_set():
            time.sleep(SECOND)


if __name__ == "__main__":
    try:
        opts, args = getopt.getopt(sys.argv[1:], 'd')
    except getopt.error, e:
        usage(1, e)

    for opt, arg in opts:
        if opt in ('-d',):
            do_debug = True

    multiprocessing.freeze_support()

    yastat_cfg, nagios_cfg, domain = load_cfg()

    threads = [
        stat_thread(yastat_cfg=yastat_cfg, nagios_cfg=nagios_cfg, domain=domain),
    ]

    for k, v in nagios_cfg.iteritems():
        if 'is_func' in v:
            threads.append(func_thread(nagios_cfg=nagios_cfg))
            break

    for thread in threads:
        thread.start()
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt, e:
        do_exit.set()
    finally:
        for thread in threads:
            thread.join()
